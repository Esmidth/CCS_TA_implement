{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import utilities\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "from consts import sensor_lat as lat\n",
    "from consts import sensor_log as log\n",
    "from consts import valid_sensor_res_10 as valid_sensor_list\n",
    "from consts import valid_sensor_res_10_old as valid_sensor_list_old\n",
    "from consts import sensor_day_seconds as day_seconds\n",
    "from consts import sensor_week_seconds as week_seconds \n",
    "from consts import sensor_start_time_unix as start_time\n",
    "from consts import sensor_end_time_unix as end_time\n",
    "from consts import sensor_epoch_length as epoch_length\n",
    "from consts import sensor_optimal_time_interval as optimal_time_interval\n",
    "from consts import sensor_loc_pic as loc_pic\n",
    "from consts import sensor_drop_list as drop_list\n",
    "import consts\n",
    "import time\n",
    "import pickle\n",
    "import copy\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ss_utilities import dataset_read\n",
    "from ss_utilities import dataset_write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = np.arange(start_time,end_time+optimal_time_interval,optimal_time_interval)\n",
    "unix_column = 'Time since the epoch [s]'\n",
    "idd = 'Station ID'\n",
    "a_temperature = 'Ambient Temperature'\n",
    "s_temperature = 'Surface Temperature'\n",
    "data_index = ['a_temperature_mean','a_temperature_std','a_temperature_array','sub_df_list_optimal_index','time_stamp',]\n",
    "df_dict = {'rb_optimal':5959,'optimal':5959,'df_list':20160}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('dataset.hdf5','r') as f:\n",
    "     a_temperature_mean = f[data_index[0]][:]\n",
    "     a_temperature_std = f[data_index[1]][:]\n",
    "     a_temperature_array = f[data_index[2]][:]\n",
    "     sub_df_list_optimal_index = f[data_index[3]][:]\n",
    "     time_stamp = f[data_index[4]][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet,self).__init__()\n",
    "        n_features = 44\n",
    "        n_out = 1\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(256,n_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = DiscriminatorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet,self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 44\n",
    "\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features,256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(256,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(512,n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = GeneratorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = Variable(torch.randn(size,100,dtype=torch.float32))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([44, 100])"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "noise(44).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = noise(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n12 = generator(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    data = Variable(torch.ones(size,1,dtype=torch.float32))\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    data = Variable(torch.zeros(size,1,dtype=torch.float32))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer,real_data,fake_data):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    N = real_data.size(0)\n",
    "\n",
    "    prediction_real = dis(real_data)\n",
    "    error_real = loss(prediction_real,ones_target(N))\n",
    "    error_real.backward()\n",
    "\n",
    "    prediction_fake = dis(fake_data)\n",
    "    error_fake = loss(prediction_fake,zeros_target(N))\n",
    "\n",
    "    error_fake.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return error_real+error_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer,fake_data):\n",
    "    N = fake_data.size(0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    prediction = dis(fake_data)\n",
    "\n",
    "    error = loss(prediction,ones_target(N))\n",
    "\n",
    "    error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-87-d8146acb3ad1>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-87-d8146acb3ad1>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for epoch in range(num_epochs):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch,(real_batch) in enumerate(train_dataloader):\n",
    "        N = real_batch.size(0)\n",
    "\n",
    "        real_batch = real_batch - real_batch.mean(axis=0)\n",
    "        real_data = Variable(real_batch)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitskleran23conda0ab411ec2f194e23aec19adfa46b0b62",
   "display_name": "Python 3.7.3 64-bit ('skleran23': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}